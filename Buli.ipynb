{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Buli.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "td_N14kMKogn"
      },
      "source": [
        "### Scrape the results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g4LNGWkbqkCw",
        "outputId": "a933763a-f30e-4465-81e9-59326264d017"
      },
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle as pkl\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7JO161l0bp_O"
      },
      "source": [
        "path_data = '/content/drive/My Drive/Python_stuff/Bundesliga21/'"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-U3JMBcUqhff"
      },
      "source": [
        "teams = {}\n",
        "teams[\"Augsburg\"] = 1\n",
        "teams[\"Bayern\"] = 2\n",
        "teams[\"Bielefeld\"] = 3\n",
        "teams[\"Berlin\"] = 4\n",
        "teams[\"Bochum\"] = 5\n",
        "teams[\"Dortmund\"] = 6\n",
        "teams[\"Frankfurt\"] = 7\n",
        "teams[\"Freiburg\"] = 8\n",
        "teams[\"Fürth\"] = 9\n",
        "teams[\"Hoffenheim\"] = 10\n",
        "teams[\"Köln\"] = 11\n",
        "teams[\"Leipzig\"] = 12\n",
        "teams[\"Leverkusen\"] = 13\n",
        "teams[\"Mainz\"] = 14\n",
        "teams[\"M'gladbach\"] = 15 \n",
        "teams[\"Stuttgart\"] = 16\n",
        "teams[\"Union Berlin\"] = 17\n",
        "teams[\"Wolfsburg\"] = 18"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y49RFmu1KfUS"
      },
      "source": [
        "# Function to scrape results\n",
        "def scrape():\n",
        "  filename = path_data + 'results.pkl'\n",
        "  spieltage = np.full([34,9,4],-1)\n",
        "  try:\n",
        "    # open spieltage\n",
        "    with open(filename,'rb') as f:\n",
        "      spieltage = pkl.load(f)\n",
        "  except:\n",
        "    pass\n",
        "  start = np.where(spieltage == -1)[0][0]\n",
        "  print(start)\n",
        "  for i in range(start,34):\n",
        "    URL = 'https://www.bundesliga.com/de/bundesliga/spieltag/2021-2022/' + str(i)\n",
        "    page = requests.get(URL)\n",
        "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
        "    \n",
        "    spieltag = np.full([9,4],-1)\n",
        "    list_games = soup.find_all(class_=\"ng-star-inserted\") #matchRow ng-star-inserted\n",
        "    for j in range(9):\n",
        "      game = BeautifulSoup(str(list_games[j]), \"html.parser\")\n",
        "      game.find_all('a', href=True)\n",
        "      gam = BeautifulSoup(str(game), \"html.parser\")\n",
        "      names = gam.find_all(class_=\"name d-none d-md-block\")\n",
        "      spieltag[j,0] = teams[names[0].text]\n",
        "      spieltag[j,3] = teams[names[1].text]\n",
        "      try:\n",
        "        spieltag[j,1] = game.find_all(class_=\"score ng-star-inserted\")[0].text\n",
        "        spieltag[j,2] = game.find_all(class_=\"score ng-star-inserted\")[1].text\n",
        "      except:\n",
        "        print('Spieltag ' + str(i) + ', Partie ' + names[0].text + ' vs. ' + names[1].text + ' not played yet!')\n",
        "    spieltage[i-1] = spieltag\n",
        "    if sum(spieltage[i-1][:,1]) == -9:\n",
        "      with open(filename,'wb') as f:\n",
        "        pkl.dump(spieltage, f)\n",
        "        print('Stop scraping because the matches are not played.')\n",
        "      break\n",
        "  # with open(filename,'wb') as f:\n",
        "  #   pkl.dump(spieltage, f)\n",
        "  return spieltage\n",
        "spieltage = scrape()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filename = path_data + 'results.pkl'\n",
        "spieltage = np.full([34,9,4],-1)\n",
        "with open(filename,'rb') as f:\n",
        "  spieltage = pkl.load(f)\n",
        "print(spieltage)"
      ],
      "metadata": {
        "id": "mSwPMnrhIeoB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "SnXSNTjxQ4xK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "teams = {}\n",
        "teams[\"augsburg\"] = 1\n",
        "teams[\"bayern\"] = 2\n",
        "teams[\"bielefeld\"] = 3\n",
        "teams[\"herthabsc\"] = 4\n",
        "teams[\"vflbochum\"] = 5\n",
        "teams[\"dortmund\"] = 6\n",
        "teams[\"frankfurt\"] = 7\n",
        "teams[\"freiburg\"] = 8\n",
        "teams[\"fuerth\"] = 9\n",
        "teams[\"hoffenheim\"] = 10\n",
        "teams[\"koeln\"] = 11\n",
        "teams[\"rbleipzig\"] = 12\n",
        "teams[\"leverkusen\"] = 13\n",
        "teams[\"mainz\"] = 14\n",
        "teams[\"mgladbach\"] = 15 \n",
        "teams[\"stuttgart\"] = 16\n",
        "teams[\"unionberlin\"] = 17\n",
        "teams[\"wolfsburg\"] = 18"
      ],
      "metadata": {
        "id": "ljzGN-LLIfHz"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pa2OJfv_v9HW"
      },
      "source": [
        "def scrape_results(spieltag):\n",
        "  filename = path_data + 'results_table.pkl'\n",
        "  results_table = np.zeros((34,131,18))\n",
        "  try:\n",
        "    # open spieltage\n",
        "    with open(filename,'rb') as f:\n",
        "      results_table = pkl.load(f)\n",
        "  except:\n",
        "    pass\n",
        "  for s in range(34):\n",
        "    if sum(sum(results_table[s])) == 0:\n",
        "      print('nächster Spieltag: {}'.format(s+1))\n",
        "      break\n",
        "  for i in range(s+1,spieltag+1):\n",
        "    URL = 'https://www.fussballdaten.de/bundesliga/2022/' + str(i) + '/'\n",
        "    page = requests.get(URL)\n",
        "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
        "    matches = soup.find_all(class_=\"spiele-row detils\")\n",
        "    print('Spieltag: {}'.format(i))\n",
        "    for j in range(len(matches)):\n",
        "      match = BeautifulSoup(str(matches[j]), \"html.parser\")\n",
        "      match.find_all(class_=\"ergebnis\")\n",
        "      link = BeautifulSoup(str(match), \"html.parser\")\n",
        "      #link.find('a', href=True)\n",
        "      links = []\n",
        "      for a in link.find_all('a', href=True): \n",
        "          if a.text: \n",
        "              links.append(a['href'])\n",
        "      # print(links[1])\n",
        "      heim = links[1].replace('/bundesliga/2022/' + str(i) + '/', '').split('-')[0]\n",
        "      ausw = links[1].replace('/bundesliga/2022/' + str(i) + '/', '').split('-')[1].replace('/','')\n",
        "      print('Heimmannschaft: {}'.format(heim))\n",
        "\n",
        "      teams[heim]\n",
        "      print('Auswärtsmannschaft: {}'.format(ausw))\n",
        "\n",
        "      URL = 'https://www.fussballdaten.de' + links[1]\n",
        "      page = requests.get(URL)\n",
        "      soup = BeautifulSoup(page.content, \"html.parser\")\n",
        "      soup2 = soup.find_all(class_=\"ergebnis-timeline\")\n",
        "      soup2 = BeautifulSoup(str(soup2), \"html.parser\")\n",
        "      time = soup2.find_all(class_=\"timeline-badge\")\n",
        "      time = [ele.text for ele in time]\n",
        "\n",
        "      game = np.zeros((131,2)) # 45 + 20, 45 + 20\n",
        "      game[0][0] = teams[heim]\n",
        "      game[0][1] = teams[ausw]\n",
        "      goal = soup2.find_all(class_=\"timeline-panel\")\n",
        "      goal = [ele for ele in goal if 'class=\"icon-red-card icon-shadow fs16\"' not in str(ele) and 'class=\"icon-yellow-red-card icon-shadow fs16\"' not in str(ele)]\n",
        "      for k in range(len(goal)):\n",
        "        # print(time[i][:2],int(time[i].split('+')[i]))\n",
        "        # print(time[i])\n",
        "        min = int(time[k].split(\"'\")[0]) # min\n",
        "        if len(time[k]) > 3:\n",
        "          overtime = int(time[k].split('+')[1]) # overtime\n",
        "        else: overtime = 0\n",
        "\n",
        "        # print(goal[i].text)\n",
        "        first = goal[k].text.split(':')[0]\n",
        "        second = goal[k].text.split(':')[1]\n",
        "        try:\n",
        "          goa1 = int(first[-2:])\n",
        "        except:\n",
        "          goa1 = int(first[-1:])\n",
        "        # print(goa1)\n",
        "        try:\n",
        "          int(second[:2])\n",
        "          goa2 = int(second[:2])\n",
        "        except:\n",
        "          goa2= int(second[:1])\n",
        "        # print(goa2)\n",
        "        if min < 45:\n",
        "          row = min\n",
        "        elif min == 45:\n",
        "          row = min + overtime\n",
        "        elif min > 45 and min < 90:\n",
        "          row = min + 20\n",
        "        elif min == 90:\n",
        "          row = min + overtime + 20\n",
        "\n",
        "        game[row][0] = goa1\n",
        "        game[row][1] = goa2\n",
        "      for k in range(1,130):\n",
        "        if game[k+1][0] == 0 and game[k+1][1] == 0:\n",
        "          game[k+1][0] = game[k][0]\n",
        "          game[k+1][1] = game[k][1]\n",
        "      if j == 0:\n",
        "        games = game\n",
        "      else: games = np.append(games, game, axis=1)\n",
        "    results_table[i-1] = games\n",
        "  filename = path_data + 'results_table.pkl'\n",
        "  with open(filename,'wb') as f:\n",
        "    pkl.dump(results_table, f)\n",
        "  # return results_table"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scrape_results(22)"
      ],
      "metadata": {
        "id": "hOowgY4VA52U"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}